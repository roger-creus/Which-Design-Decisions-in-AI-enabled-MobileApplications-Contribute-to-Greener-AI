{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b178ca5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-17T14:37:09.932551Z",
     "iopub.status.busy": "2021-12-17T14:37:09.928705Z",
     "iopub.status.idle": "2021-12-17T14:37:09.951418Z",
     "shell.execute_reply": "2021-12-17T14:37:09.952044Z",
     "shell.execute_reply.started": "2021-12-15T09:47:04.551436Z"
    },
    "papermill": {
     "duration": 0.047774,
     "end_time": "2021-12-17T14:37:09.952349",
     "exception": false,
     "start_time": "2021-12-17T14:37:09.904575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazonreviews/test.ft.txt.bz2\n",
      "/kaggle/input/amazonreviews/train.ft.txt.bz2\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9399df2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:37:09.998461Z",
     "iopub.status.busy": "2021-12-17T14:37:09.997768Z",
     "iopub.status.idle": "2021-12-17T14:37:15.517491Z",
     "shell.execute_reply": "2021-12-17T14:37:15.517917Z",
     "shell.execute_reply.started": "2021-12-15T09:47:04.602525Z"
    },
    "papermill": {
     "duration": 5.543959,
     "end_time": "2021-12-17T14:37:15.518082",
     "exception": false,
     "start_time": "2021-12-17T14:37:09.974123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6b0ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:37:15.553284Z",
     "iopub.status.busy": "2021-12-17T14:37:15.552610Z",
     "iopub.status.idle": "2021-12-17T14:37:15.555074Z",
     "shell.execute_reply": "2021-12-17T14:37:15.554663Z",
     "shell.execute_reply.started": "2021-12-15T09:47:11.616003Z"
    },
    "papermill": {
     "duration": 0.021266,
     "end_time": "2021-12-17T14:37:15.555171",
     "exception": false,
     "start_time": "2021-12-17T14:37:15.533905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0ed875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:37:15.592390Z",
     "iopub.status.busy": "2021-12-17T14:37:15.591633Z",
     "iopub.status.idle": "2021-12-17T14:37:15.594164Z",
     "shell.execute_reply": "2021-12-17T14:37:15.593775Z",
     "shell.execute_reply.started": "2021-12-15T09:47:11.628463Z"
    },
    "papermill": {
     "duration": 0.023165,
     "end_time": "2021-12-17T14:37:15.594265",
     "exception": false,
     "start_time": "2021-12-17T14:37:15.571100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labels_texts(file):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for line in bz2.BZ2File(file):\n",
    "        x = line.decode(\"utf-8\")\n",
    "        labels.append(int(x[9]) - 1)\n",
    "        texts.append(x[10:].strip())\n",
    "    return np.array(labels), texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37e4930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:37:15.629613Z",
     "iopub.status.busy": "2021-12-17T14:37:15.629092Z",
     "iopub.status.idle": "2021-12-17T14:39:17.386438Z",
     "shell.execute_reply": "2021-12-17T14:39:17.385868Z",
     "shell.execute_reply.started": "2021-12-15T09:47:11.649092Z"
    },
    "papermill": {
     "duration": 121.776445,
     "end_time": "2021-12-17T14:39:17.386593",
     "exception": false,
     "start_time": "2021-12-17T14:37:15.610148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_label, train_text = labels_texts('../input/amazonreviews/train.ft.txt.bz2')\n",
    "test_label, test_text = labels_texts('../input/amazonreviews/test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76279512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:39:17.423504Z",
     "iopub.status.busy": "2021-12-17T14:39:17.422883Z",
     "iopub.status.idle": "2021-12-17T14:39:17.425661Z",
     "shell.execute_reply": "2021-12-17T14:39:17.426089Z",
     "shell.execute_reply.started": "2021-12-15T09:49:33.606373Z"
    },
    "papermill": {
     "duration": 0.023311,
     "end_time": "2021-12-17T14:39:17.426208",
     "exception": false,
     "start_time": "2021-12-17T14:39:17.402897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n"
     ]
    }
   ],
   "source": [
    "print(train_label[0])\n",
    "print(train_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5bf48b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:39:17.460970Z",
     "iopub.status.busy": "2021-12-17T14:39:17.460147Z",
     "iopub.status.idle": "2021-12-17T14:39:17.465755Z",
     "shell.execute_reply": "2021-12-17T14:39:17.466182Z",
     "shell.execute_reply.started": "2021-12-15T09:49:33.618974Z"
    },
    "papermill": {
     "duration": 0.024222,
     "end_time": "2021-12-17T14:39:17.466323",
     "exception": false,
     "start_time": "2021-12-17T14:39:17.442101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "not_numChar = re.compile(r'[\\W]')\n",
    "no_encode = re.compile(r'[^a-z0-1\\s]')\n",
    "def normalisation(texts):\n",
    "    norm_text = []\n",
    "    for word in texts:\n",
    "        lower = word.lower()\n",
    "        not_punct = not_numChar.sub(r' ', lower)\n",
    "        exclude_no_encode = no_encode.sub(r'', not_punct)\n",
    "        norm_text.append(exclude_no_encode)\n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f0037e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:39:17.547029Z",
     "iopub.status.busy": "2021-12-17T14:39:17.506026Z",
     "iopub.status.idle": "2021-12-17T14:42:19.882826Z",
     "shell.execute_reply": "2021-12-17T14:42:19.882295Z",
     "shell.execute_reply.started": "2021-12-15T09:49:33.631996Z"
    },
    "papermill": {
     "duration": 182.40048,
     "end_time": "2021-12-17T14:42:19.882968",
     "exception": false,
     "start_time": "2021-12-17T14:39:17.482488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_text = normalisation(train_text)\n",
    "test_text = normalisation(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b748784c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:42:19.922704Z",
     "iopub.status.busy": "2021-12-17T14:42:19.921135Z",
     "iopub.status.idle": "2021-12-17T14:42:19.925200Z",
     "shell.execute_reply": "2021-12-17T14:42:19.924602Z",
     "shell.execute_reply.started": "2021-12-15T09:52:56.562418Z"
    },
    "papermill": {
     "duration": 0.024336,
     "end_time": "2021-12-17T14:42:19.925349",
     "exception": false,
     "start_time": "2021-12-17T14:42:19.901013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuning even for the non gamer  this sound track was beautiful  it paints the senery in your mind so well i would recomend it even to people who hate vid  game music  i have played the game chrono cross but out of all of the games i have ever played it has the best music  it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras  it would impress anyone who cares to listen    \n"
     ]
    }
   ],
   "source": [
    "print(train_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d145a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:42:19.964572Z",
     "iopub.status.busy": "2021-12-17T14:42:19.962811Z",
     "iopub.status.idle": "2021-12-17T14:42:19.970763Z",
     "shell.execute_reply": "2021-12-17T14:42:19.971203Z",
     "shell.execute_reply.started": "2021-12-15T09:52:56.574224Z"
    },
    "papermill": {
     "duration": 0.028905,
     "end_time": "2021-12-17T14:42:19.971348",
     "exception": false,
     "start_time": "2021-12-17T14:42:19.942443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = np.array(train_label)\n",
    "y_test = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be84ebd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:42:20.009743Z",
     "iopub.status.busy": "2021-12-17T14:42:20.009108Z",
     "iopub.status.idle": "2021-12-17T14:42:20.012098Z",
     "shell.execute_reply": "2021-12-17T14:42:20.012540Z",
     "shell.execute_reply.started": "2021-12-15T09:52:56.598686Z"
    },
    "papermill": {
     "duration": 0.024945,
     "end_time": "2021-12-17T14:42:20.012659",
     "exception": false,
     "start_time": "2021-12-17T14:42:19.987714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb85e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:42:20.058201Z",
     "iopub.status.busy": "2021-12-17T14:42:20.053077Z",
     "iopub.status.idle": "2021-12-17T14:46:14.624389Z",
     "shell.execute_reply": "2021-12-17T14:46:14.624806Z",
     "shell.execute_reply.started": "2021-12-15T09:52:56.818906Z"
    },
    "papermill": {
     "duration": 234.595354,
     "end_time": "2021-12-17T14:46:14.624956",
     "exception": false,
     "start_time": "2021-12-17T14:42:20.029602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size : 905946\n"
     ]
    }
   ],
   "source": [
    "max_features = 8192\n",
    "maxlen = 128\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f1640e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:46:14.664131Z",
     "iopub.status.busy": "2021-12-17T14:46:14.663410Z",
     "iopub.status.idle": "2021-12-17T14:46:15.543609Z",
     "shell.execute_reply": "2021-12-17T14:46:15.543102Z",
     "shell.execute_reply.started": "2021-12-15T09:58:13.726016Z"
    },
    "papermill": {
     "duration": 0.901179,
     "end_time": "2021-12-17T14:46:15.543747",
     "exception": false,
     "start_time": "2021-12-17T14:46:14.642568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "with open('amazon_dictionary.txt', 'w') as file:\n",
    "    for key in word_index.keys():\n",
    "        file.write(key + \" \" + str(word_index[key]) + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9dbe88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:46:15.652561Z",
     "iopub.status.busy": "2021-12-17T14:46:15.616712Z",
     "iopub.status.idle": "2021-12-17T14:49:44.807557Z",
     "shell.execute_reply": "2021-12-17T14:49:44.806987Z",
     "shell.execute_reply.started": "2021-12-15T09:58:14.779469Z"
    },
    "papermill": {
     "duration": 209.246505,
     "end_time": "2021-12-17T14:49:44.807708",
     "exception": false,
     "start_time": "2021-12-17T14:46:15.561203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_token = tokenizer.texts_to_sequences(train_text)\n",
    "testing_token = tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f3ab170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:49:44.884960Z",
     "iopub.status.busy": "2021-12-17T14:49:44.874675Z",
     "iopub.status.idle": "2021-12-17T14:51:00.600654Z",
     "shell.execute_reply": "2021-12-17T14:51:00.599662Z",
     "shell.execute_reply.started": "2021-12-15T10:02:34.793198Z"
    },
    "papermill": {
     "duration": 75.775596,
     "end_time": "2021-12-17T14:51:00.600807",
     "exception": false,
     "start_time": "2021-12-17T14:49:44.825211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(training_token, maxlen = maxlen, padding = 'post')\n",
    "x_test = pad_sequences(testing_token, maxlen = maxlen, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "456b2f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:51:00.640913Z",
     "iopub.status.busy": "2021-12-17T14:51:00.640224Z",
     "iopub.status.idle": "2021-12-17T14:51:02.334909Z",
     "shell.execute_reply": "2021-12-17T14:51:02.334413Z",
     "shell.execute_reply.started": "2021-12-15T10:03:54.502031Z"
    },
    "papermill": {
     "duration": 1.717098,
     "end_time": "2021-12-17T14:51:02.335036",
     "exception": false,
     "start_time": "2021-12-17T14:51:00.617938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last = True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b643ab63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:51:02.382947Z",
     "iopub.status.busy": "2021-12-17T14:51:02.382155Z",
     "iopub.status.idle": "2021-12-17T14:51:02.384654Z",
     "shell.execute_reply": "2021-12-17T14:51:02.384089Z",
     "shell.execute_reply.started": "2021-12-15T10:19:14.696233Z"
    },
    "papermill": {
     "duration": 0.032391,
     "end_time": "2021-12-17T14:51:02.384764",
     "exception": false,
     "start_time": "2021-12-17T14:51:02.352373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.2):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim, drop_prob)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(embedding_dim, 2, hidden_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim * 128 , 1)\n",
    "\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src) * math.sqrt(self.embedding_dim)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        \n",
    "        output = self.sigmoid(self.fc(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25d52134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:51:02.423253Z",
     "iopub.status.busy": "2021-12-17T14:51:02.422761Z",
     "iopub.status.idle": "2021-12-17T14:51:02.426402Z",
     "shell.execute_reply": "2021-12-17T14:51:02.425904Z",
     "shell.execute_reply.started": "2021-12-15T10:04:00.284359Z"
    },
    "papermill": {
     "duration": 0.024535,
     "end_time": "2021-12-17T14:51:02.426504",
     "exception": false,
     "start_time": "2021-12-17T14:51:02.401969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e511b506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:51:02.466295Z",
     "iopub.status.busy": "2021-12-17T14:51:02.465713Z",
     "iopub.status.idle": "2021-12-17T14:51:07.242169Z",
     "shell.execute_reply": "2021-12-17T14:51:07.243344Z",
     "shell.execute_reply.started": "2021-12-15T10:19:04.882323Z"
    },
    "papermill": {
     "duration": 4.800074,
     "end_time": "2021-12-17T14:51:07.243564",
     "exception": false,
     "start_time": "2021-12-17T14:51:02.443490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9070037\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "output_size = 1\n",
    "embedding_dim = 10\n",
    "hidden_dim = 32\n",
    "n_layers = 8\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "print(model_params(model))\n",
    "lr=0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5720f3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T14:51:07.316791Z",
     "iopub.status.busy": "2021-12-17T14:51:07.315931Z",
     "iopub.status.idle": "2021-12-17T17:19:59.532696Z",
     "shell.execute_reply": "2021-12-17T17:19:59.533427Z",
     "shell.execute_reply.started": "2021-12-15T10:19:07.623429Z"
    },
    "papermill": {
     "duration": 8932.257946,
     "end_time": "2021-12-17T17:19:59.533666",
     "exception": false,
     "start_time": "2021-12-17T14:51:07.275720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Step: 500... Loss: 0.680820... Val Loss: 0.686899\n",
      "Validation loss decreased (inf --> 0.686899).  Saving model ...\n",
      "Epoch: 1/1... Step: 1000... Loss: 0.687831... Val Loss: 0.693426\n",
      "Epoch: 1/1... Step: 1500... Loss: 0.696953... Val Loss: 0.693790\n",
      "Epoch: 1/1... Step: 2000... Loss: 0.691474... Val Loss: 0.693998\n",
      "Epoch: 1/1... Step: 2500... Loss: 0.693276... Val Loss: 0.693153\n",
      "Epoch: 1/1... Step: 3000... Loss: 0.690925... Val Loss: 0.693213\n",
      "Epoch: 1/1... Step: 3500... Loss: 0.693712... Val Loss: 0.693253\n",
      "Epoch: 1/1... Step: 4000... Loss: 0.692438... Val Loss: 0.693384\n",
      "Epoch: 1/1... Step: 4500... Loss: 0.691632... Val Loss: 0.693280\n",
      "Epoch: 1/1... Step: 5000... Loss: 0.688286... Val Loss: 0.693557\n",
      "Epoch: 1/1... Step: 5500... Loss: 0.693544... Val Loss: 0.693362\n",
      "Epoch: 1/1... Step: 6000... Loss: 0.695422... Val Loss: 0.693847\n",
      "Epoch: 1/1... Step: 6500... Loss: 0.689784... Val Loss: 0.693170\n",
      "Epoch: 1/1... Step: 7000... Loss: 0.687637... Val Loss: 0.701998\n",
      "Epoch: 1/1... Step: 7500... Loss: 0.697677... Val Loss: 0.707964\n",
      "Epoch: 1/1... Step: 8000... Loss: 0.690982... Val Loss: 0.693188\n",
      "Epoch: 1/1... Step: 8500... Loss: 0.692805... Val Loss: 0.693448\n",
      "Epoch: 1/1... Step: 9000... Loss: 0.702750... Val Loss: 0.695786\n",
      "Epoch: 1/1... Step: 9500... Loss: 0.698583... Val Loss: 0.697972\n",
      "Epoch: 1/1... Step: 10000... Loss: 0.691743... Val Loss: 0.693920\n",
      "Epoch: 1/1... Step: 10500... Loss: 0.695052... Val Loss: 0.693149\n",
      "Epoch: 1/1... Step: 11000... Loss: 0.689180... Val Loss: 0.693366\n",
      "Epoch: 1/1... Step: 11500... Loss: 0.692018... Val Loss: 0.693193\n",
      "Epoch: 1/1... Step: 12000... Loss: 0.688563... Val Loss: 0.693663\n",
      "Epoch: 1/1... Step: 12500... Loss: 0.691903... Val Loss: 0.693164\n",
      "Epoch: 1/1... Step: 13000... Loss: 0.702438... Val Loss: 0.694251\n",
      "Epoch: 1/1... Step: 13500... Loss: 0.689030... Val Loss: 0.694262\n",
      "Epoch: 1/1... Step: 14000... Loss: 0.739567... Val Loss: 0.698266\n",
      "Epoch: 1/1... Step: 14500... Loss: 0.700158... Val Loss: 0.693914\n",
      "Epoch: 1/1... Step: 15000... Loss: 0.697475... Val Loss: 0.693147\n",
      "Epoch: 1/1... Step: 15500... Loss: 0.692494... Val Loss: 0.694586\n",
      "Epoch: 1/1... Step: 16000... Loss: 0.698960... Val Loss: 0.693908\n",
      "Epoch: 1/1... Step: 16500... Loss: 0.699378... Val Loss: 0.693549\n",
      "Epoch: 1/1... Step: 17000... Loss: 0.692225... Val Loss: 0.693628\n",
      "Epoch: 1/1... Step: 17500... Loss: 0.675105... Val Loss: 0.703709\n",
      "Epoch: 1/1... Step: 18000... Loss: 0.694489... Val Loss: 0.693821\n",
      "Epoch: 1/1... Step: 18500... Loss: 0.698848... Val Loss: 0.693299\n",
      "Epoch: 1/1... Step: 19000... Loss: 0.702064... Val Loss: 0.694551\n",
      "Epoch: 1/1... Step: 19500... Loss: 0.694923... Val Loss: 0.693329\n",
      "Epoch: 1/1... Step: 20000... Loss: 0.694041... Val Loss: 0.693415\n",
      "Epoch: 1/1... Step: 20500... Loss: 0.711805... Val Loss: 0.693448\n",
      "Epoch: 1/1... Step: 21000... Loss: 0.694616... Val Loss: 0.694201\n",
      "Epoch: 1/1... Step: 21500... Loss: 0.692227... Val Loss: 0.693329\n",
      "Epoch: 1/1... Step: 22000... Loss: 0.695260... Val Loss: 0.696944\n",
      "Epoch: 1/1... Step: 22500... Loss: 0.758271... Val Loss: 0.693165\n",
      "Epoch: 1/1... Step: 23000... Loss: 0.693381... Val Loss: 0.693324\n",
      "Epoch: 1/1... Step: 23500... Loss: 0.689667... Val Loss: 0.693627\n",
      "Epoch: 1/1... Step: 24000... Loss: 0.695148... Val Loss: 0.693150\n",
      "Epoch: 1/1... Step: 24500... Loss: 0.692449... Val Loss: 0.693154\n",
      "Epoch: 1/1... Step: 25000... Loss: 0.710529... Val Loss: 0.703168\n",
      "Epoch: 1/1... Step: 25500... Loss: 0.691960... Val Loss: 0.693173\n",
      "Epoch: 1/1... Step: 26000... Loss: 0.695513... Val Loss: 0.693254\n",
      "Epoch: 1/1... Step: 26500... Loss: 0.684495... Val Loss: 0.699288\n",
      "Epoch: 1/1... Step: 27000... Loss: 0.695471... Val Loss: 0.693907\n",
      "Epoch: 1/1... Step: 27500... Loss: 0.691522... Val Loss: 0.693936\n",
      "Epoch: 1/1... Step: 28000... Loss: 0.728092... Val Loss: 0.693808\n",
      "Epoch: 1/1... Step: 28500... Loss: 0.709117... Val Loss: 0.695311\n",
      "Epoch: 1/1... Step: 29000... Loss: 0.693409... Val Loss: 0.693160\n",
      "Epoch: 1/1... Step: 29500... Loss: 0.696990... Val Loss: 0.694529\n",
      "Epoch: 1/1... Step: 30000... Loss: 0.688533... Val Loss: 0.693319\n",
      "Epoch: 1/1... Step: 30500... Loss: 0.691936... Val Loss: 0.693438\n",
      "Epoch: 1/1... Step: 31000... Loss: 0.707000... Val Loss: 0.699510\n",
      "Epoch: 1/1... Step: 31500... Loss: 0.692386... Val Loss: 0.693176\n",
      "Epoch: 1/1... Step: 32000... Loss: 0.691347... Val Loss: 0.693214\n",
      "Epoch: 1/1... Step: 32500... Loss: 0.692403... Val Loss: 0.693148\n",
      "Epoch: 1/1... Step: 33000... Loss: 0.694832... Val Loss: 0.694771\n",
      "Epoch: 1/1... Step: 33500... Loss: 0.691252... Val Loss: 0.693147\n",
      "Epoch: 1/1... Step: 34000... Loss: 0.693556... Val Loss: 0.693165\n",
      "Epoch: 1/1... Step: 34500... Loss: 0.692297... Val Loss: 0.693563\n",
      "Epoch: 1/1... Step: 35000... Loss: 0.696732... Val Loss: 0.693373\n",
      "Epoch: 1/1... Step: 35500... Loss: 0.704911... Val Loss: 0.693656\n",
      "Epoch: 1/1... Step: 36000... Loss: 0.686181... Val Loss: 0.719366\n",
      "Epoch: 1/1... Step: 36500... Loss: 0.692086... Val Loss: 0.693199\n",
      "Epoch: 1/1... Step: 37000... Loss: 0.692967... Val Loss: 0.693248\n",
      "Epoch: 1/1... Step: 37500... Loss: 0.701947... Val Loss: 0.702164\n",
      "Epoch: 1/1... Step: 38000... Loss: 0.690811... Val Loss: 0.693159\n",
      "Epoch: 1/1... Step: 38500... Loss: 0.701132... Val Loss: 0.693216\n",
      "Epoch: 1/1... Step: 39000... Loss: 0.694386... Val Loss: 0.693216\n",
      "Epoch: 1/1... Step: 39500... Loss: 0.694667... Val Loss: 0.693555\n",
      "Epoch: 1/1... Step: 40000... Loss: 0.692233... Val Loss: 0.694757\n",
      "Epoch: 1/1... Step: 40500... Loss: 0.687843... Val Loss: 0.695547\n",
      "Epoch: 1/1... Step: 41000... Loss: 0.694309... Val Loss: 0.693189\n",
      "Epoch: 1/1... Step: 41500... Loss: 0.691747... Val Loss: 0.693997\n",
      "Epoch: 1/1... Step: 42000... Loss: 0.703902... Val Loss: 0.694045\n",
      "Epoch: 1/1... Step: 42500... Loss: 0.680389... Val Loss: 0.695222\n",
      "Epoch: 1/1... Step: 43000... Loss: 0.753056... Val Loss: 0.708339\n",
      "Epoch: 1/1... Step: 43500... Loss: 0.695457... Val Loss: 0.693148\n",
      "Epoch: 1/1... Step: 44000... Loss: 0.694011... Val Loss: 0.693154\n",
      "Epoch: 1/1... Step: 44500... Loss: 0.692905... Val Loss: 0.693150\n",
      "Epoch: 1/1... Step: 45000... Loss: 0.684882... Val Loss: 0.696647\n",
      "Epoch: 1/1... Step: 45500... Loss: 0.704449... Val Loss: 0.699383\n",
      "Epoch: 1/1... Step: 46000... Loss: 0.693400... Val Loss: 0.696140\n",
      "Epoch: 1/1... Step: 46500... Loss: 0.683670... Val Loss: 0.695678\n",
      "Epoch: 1/1... Step: 47000... Loss: 0.771577... Val Loss: 0.707531\n",
      "Epoch: 1/1... Step: 47500... Loss: 0.696708... Val Loss: 0.693742\n",
      "Epoch: 1/1... Step: 48000... Loss: 0.694167... Val Loss: 0.693148\n",
      "Epoch: 1/1... Step: 48500... Loss: 0.692728... Val Loss: 0.693433\n",
      "Epoch: 1/1... Step: 49000... Loss: 0.701765... Val Loss: 0.693523\n",
      "Epoch: 1/1... Step: 49500... Loss: 0.684654... Val Loss: 0.696055\n",
      "Epoch: 1/1... Step: 50000... Loss: 0.701931... Val Loss: 0.704553\n",
      "Epoch: 1/1... Step: 50500... Loss: 0.700347... Val Loss: 0.694676\n",
      "Epoch: 1/1... Step: 51000... Loss: 0.713998... Val Loss: 0.694397\n",
      "Epoch: 1/1... Step: 51500... Loss: 0.693300... Val Loss: 0.693575\n",
      "Epoch: 1/1... Step: 52000... Loss: 0.689546... Val Loss: 0.693176\n",
      "Epoch: 1/1... Step: 52500... Loss: 0.694056... Val Loss: 0.693288\n",
      "Epoch: 1/1... Step: 53000... Loss: 0.683132... Val Loss: 0.699330\n",
      "Epoch: 1/1... Step: 53500... Loss: 0.688095... Val Loss: 0.694159\n",
      "Epoch: 1/1... Step: 54000... Loss: 0.696958... Val Loss: 0.693268\n",
      "Epoch: 1/1... Step: 54500... Loss: 0.724526... Val Loss: 0.697356\n",
      "Epoch: 1/1... Step: 55000... Loss: 0.697204... Val Loss: 0.693801\n",
      "Epoch: 1/1... Step: 55500... Loss: 0.692381... Val Loss: 0.693500\n",
      "Epoch: 1/1... Step: 56000... Loss: 0.693230... Val Loss: 0.693603\n",
      "Epoch: 1/1... Step: 56500... Loss: 0.691513... Val Loss: 0.693619\n",
      "Epoch: 1/1... Step: 57000... Loss: 0.692116... Val Loss: 0.693155\n",
      "Epoch: 1/1... Step: 57500... Loss: 0.691669... Val Loss: 0.693660\n",
      "Epoch: 1/1... Step: 58000... Loss: 0.695124... Val Loss: 0.694956\n",
      "Epoch: 1/1... Step: 58500... Loss: 0.693667... Val Loss: 0.693565\n",
      "Epoch: 1/1... Step: 59000... Loss: 0.700362... Val Loss: 0.693328\n",
      "Epoch: 1/1... Step: 59500... Loss: 0.690402... Val Loss: 0.693706\n",
      "Epoch: 1/1... Step: 60000... Loss: 0.779296... Val Loss: 0.719277\n",
      "Epoch: 1/1... Step: 60500... Loss: 0.693168... Val Loss: 0.694733\n",
      "Epoch: 1/1... Step: 61000... Loss: 0.702278... Val Loss: 0.694061\n",
      "Epoch: 1/1... Step: 61500... Loss: 0.694701... Val Loss: 0.695020\n",
      "Epoch: 1/1... Step: 62000... Loss: 0.699735... Val Loss: 0.694877\n",
      "Epoch: 1/1... Step: 62500... Loss: 0.692437... Val Loss: 0.693150\n",
      "Epoch: 1/1... Step: 63000... Loss: 0.695057... Val Loss: 0.695334\n",
      "Epoch: 1/1... Step: 63500... Loss: 0.700760... Val Loss: 0.694492\n",
      "Epoch: 1/1... Step: 64000... Loss: 0.692596... Val Loss: 0.697344\n",
      "Epoch: 1/1... Step: 64500... Loss: 0.710299... Val Loss: 0.696611\n",
      "Epoch: 1/1... Step: 65000... Loss: 0.694308... Val Loss: 0.694252\n",
      "Epoch: 1/1... Step: 65500... Loss: 0.693472... Val Loss: 0.693161\n",
      "Epoch: 1/1... Step: 66000... Loss: 0.692037... Val Loss: 0.694011\n",
      "Epoch: 1/1... Step: 66500... Loss: 0.700033... Val Loss: 0.693147\n",
      "Epoch: 1/1... Step: 67000... Loss: 0.830750... Val Loss: 0.695913\n",
      "Epoch: 1/1... Step: 67500... Loss: 0.692256... Val Loss: 0.693503\n",
      "Epoch: 1/1... Step: 68000... Loss: 0.693137... Val Loss: 0.693171\n",
      "Epoch: 1/1... Step: 68500... Loss: 0.695239... Val Loss: 0.700388\n",
      "Epoch: 1/1... Step: 69000... Loss: 0.691435... Val Loss: 0.697355\n",
      "Epoch: 1/1... Step: 69500... Loss: 0.666320... Val Loss: 0.700787\n",
      "Epoch: 1/1... Step: 70000... Loss: 0.693956... Val Loss: 0.694870\n",
      "Epoch: 1/1... Step: 70500... Loss: 0.683223... Val Loss: 0.694569\n",
      "Epoch: 1/1... Step: 71000... Loss: 0.698954... Val Loss: 0.693290\n",
      "Epoch: 1/1... Step: 71500... Loss: 0.696855... Val Loss: 0.693149\n",
      "Epoch: 1/1... Step: 72000... Loss: 0.718356... Val Loss: 0.698751\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "counter = 0\n",
    "print_every = 500\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(inputs.long())\n",
    "        \n",
    "        loss = criterion(output.squeeze(1), labels.float())\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in test_loader:\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out = model(inp.long())\n",
    "                val_loss = criterion(out.squeeze(1), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "664bafd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T17:19:59.681186Z",
     "iopub.status.busy": "2021-12-17T17:19:59.680368Z",
     "iopub.status.idle": "2021-12-17T17:19:59.720394Z",
     "shell.execute_reply": "2021-12-17T17:19:59.719949Z",
     "shell.execute_reply.started": "2021-12-15T10:04:08.106311Z"
    },
    "papermill": {
     "duration": 0.099851,
     "end_time": "2021-12-17T17:19:59.720514",
     "exception": false,
     "start_time": "2021-12-17T17:19:59.620663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5507]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I love you\"\n",
    "trial = torch.tensor(pad_sequences(tokenizer.texts_to_sequences([sentence]), maxlen = maxlen)).long().to(device)\n",
    "\n",
    "model(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d062d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T17:19:59.834837Z",
     "iopub.status.busy": "2021-12-17T17:19:59.834084Z",
     "iopub.status.idle": "2021-12-17T17:20:02.146069Z",
     "shell.execute_reply": "2021-12-17T17:20:02.145495Z",
     "shell.execute_reply.started": "2021-12-15T10:04:08.108493Z"
    },
    "papermill": {
     "duration": 2.371408,
     "end_time": "2021-12-17T17:20:02.146203",
     "exception": false,
     "start_time": "2021-12-17T17:19:59.774795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  trial,                  # model input (or a tuple for multiple inputs)\n",
    "                  \"transformer-amazon.onnx\", opset_version = 11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9783.400897,
   "end_time": "2021-12-17T17:20:05.136227",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-17T14:37:01.735330",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
