{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instrumental-double",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-09T17:33:47.857520Z",
     "iopub.status.busy": "2021-12-09T17:33:47.856926Z",
     "iopub.status.idle": "2021-12-09T17:33:47.872877Z",
     "shell.execute_reply": "2021-12-09T17:33:47.873608Z",
     "shell.execute_reply.started": "2021-12-08T21:23:43.272798Z"
    },
    "papermill": {
     "duration": 0.040388,
     "end_time": "2021-12-09T17:33:47.873873",
     "exception": false,
     "start_time": "2021-12-09T17:33:47.833485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazonreviews/test.ft.txt.bz2\n",
      "/kaggle/input/amazonreviews/train.ft.txt.bz2\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "swedish-reservation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:33:47.913394Z",
     "iopub.status.busy": "2021-12-09T17:33:47.912842Z",
     "iopub.status.idle": "2021-12-09T17:33:53.345970Z",
     "shell.execute_reply": "2021-12-09T17:33:53.345424Z",
     "shell.execute_reply.started": "2021-12-08T21:23:43.282815Z"
    },
    "papermill": {
     "duration": 5.454675,
     "end_time": "2021-12-09T17:33:53.346112",
     "exception": false,
     "start_time": "2021-12-09T17:33:47.891437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "challenging-release",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:33:53.390100Z",
     "iopub.status.busy": "2021-12-09T17:33:53.388969Z",
     "iopub.status.idle": "2021-12-09T17:33:53.390909Z",
     "shell.execute_reply": "2021-12-09T17:33:53.391403Z",
     "shell.execute_reply.started": "2021-12-08T21:23:44.433495Z"
    },
    "papermill": {
     "duration": 0.025668,
     "end_time": "2021-12-09T17:33:53.391534",
     "exception": false,
     "start_time": "2021-12-09T17:33:53.365866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vocal-curve",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:33:53.434676Z",
     "iopub.status.busy": "2021-12-09T17:33:53.433224Z",
     "iopub.status.idle": "2021-12-09T17:33:53.435203Z",
     "shell.execute_reply": "2021-12-09T17:33:53.436119Z",
     "shell.execute_reply.started": "2021-12-08T21:23:44.439536Z"
    },
    "papermill": {
     "duration": 0.026476,
     "end_time": "2021-12-09T17:33:53.436277",
     "exception": false,
     "start_time": "2021-12-09T17:33:53.409801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labels_texts(file):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for line in bz2.BZ2File(file):\n",
    "        x = line.decode(\"utf-8\")\n",
    "        labels.append(int(x[9]) - 1)\n",
    "        texts.append(x[10:].strip())\n",
    "    return np.array(labels), texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinguished-person",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:33:53.476917Z",
     "iopub.status.busy": "2021-12-09T17:33:53.476026Z",
     "iopub.status.idle": "2021-12-09T17:35:49.402364Z",
     "shell.execute_reply": "2021-12-09T17:35:49.401562Z",
     "shell.execute_reply.started": "2021-12-08T21:23:44.454135Z"
    },
    "papermill": {
     "duration": 115.948641,
     "end_time": "2021-12-09T17:35:49.402528",
     "exception": false,
     "start_time": "2021-12-09T17:33:53.453887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_label, train_text = labels_texts('../input/amazonreviews/train.ft.txt.bz2')\n",
    "test_label, test_text = labels_texts('../input/amazonreviews/test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "multiple-violin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:35:49.440854Z",
     "iopub.status.busy": "2021-12-09T17:35:49.440179Z",
     "iopub.status.idle": "2021-12-09T17:35:49.443763Z",
     "shell.execute_reply": "2021-12-09T17:35:49.443303Z",
     "shell.execute_reply.started": "2021-12-08T21:26:27.960667Z"
    },
    "papermill": {
     "duration": 0.024318,
     "end_time": "2021-12-09T17:35:49.443885",
     "exception": false,
     "start_time": "2021-12-09T17:35:49.419567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n"
     ]
    }
   ],
   "source": [
    "print(train_label[0])\n",
    "print(train_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "american-franklin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:35:49.482513Z",
     "iopub.status.busy": "2021-12-09T17:35:49.481874Z",
     "iopub.status.idle": "2021-12-09T17:35:49.484915Z",
     "shell.execute_reply": "2021-12-09T17:35:49.484480Z",
     "shell.execute_reply.started": "2021-12-08T21:26:27.967567Z"
    },
    "papermill": {
     "duration": 0.024455,
     "end_time": "2021-12-09T17:35:49.485017",
     "exception": false,
     "start_time": "2021-12-09T17:35:49.460562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "not_numChar = re.compile(r'[\\W]')\n",
    "no_encode = re.compile(r'[^a-z0-1\\s]')\n",
    "def normalisation(texts):\n",
    "    norm_text = []\n",
    "    for word in texts:\n",
    "        lower = word.lower()\n",
    "        not_punct = not_numChar.sub(r' ', lower)\n",
    "        exclude_no_encode = no_encode.sub(r'', not_punct)\n",
    "        norm_text.append(exclude_no_encode)\n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subjective-china",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:35:49.547071Z",
     "iopub.status.busy": "2021-12-09T17:35:49.541881Z",
     "iopub.status.idle": "2021-12-09T17:38:44.804205Z",
     "shell.execute_reply": "2021-12-09T17:38:44.805388Z",
     "shell.execute_reply.started": "2021-12-08T21:26:27.982804Z"
    },
    "papermill": {
     "duration": 175.303797,
     "end_time": "2021-12-09T17:38:44.805652",
     "exception": false,
     "start_time": "2021-12-09T17:35:49.501855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_text = normalisation(train_text)\n",
    "test_text = normalisation(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promising-french",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:38:44.871350Z",
     "iopub.status.busy": "2021-12-09T17:38:44.870510Z",
     "iopub.status.idle": "2021-12-09T17:38:44.873950Z",
     "shell.execute_reply": "2021-12-09T17:38:44.872092Z",
     "shell.execute_reply.started": "2021-12-08T21:29:47.899099Z"
    },
    "papermill": {
     "duration": 0.039321,
     "end_time": "2021-12-09T17:38:44.874128",
     "exception": false,
     "start_time": "2021-12-09T17:38:44.834807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuning even for the non gamer  this sound track was beautiful  it paints the senery in your mind so well i would recomend it even to people who hate vid  game music  i have played the game chrono cross but out of all of the games i have ever played it has the best music  it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras  it would impress anyone who cares to listen    \n"
     ]
    }
   ],
   "source": [
    "print(train_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "registered-packet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:38:44.947227Z",
     "iopub.status.busy": "2021-12-09T17:38:44.946303Z",
     "iopub.status.idle": "2021-12-09T17:38:44.956747Z",
     "shell.execute_reply": "2021-12-09T17:38:44.957408Z",
     "shell.execute_reply.started": "2021-12-08T21:29:47.909335Z"
    },
    "papermill": {
     "duration": 0.056488,
     "end_time": "2021-12-09T17:38:44.957597",
     "exception": false,
     "start_time": "2021-12-09T17:38:44.901109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = np.array(train_label)\n",
    "y_test = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "played-rover",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:38:45.025992Z",
     "iopub.status.busy": "2021-12-09T17:38:45.025151Z",
     "iopub.status.idle": "2021-12-09T17:38:45.030084Z",
     "shell.execute_reply": "2021-12-09T17:38:45.031104Z",
     "shell.execute_reply.started": "2021-12-08T21:29:48.14836Z"
    },
    "papermill": {
     "duration": 0.043942,
     "end_time": "2021-12-09T17:38:45.031308",
     "exception": false,
     "start_time": "2021-12-09T17:38:44.987366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unexpected-intranet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:38:45.102576Z",
     "iopub.status.busy": "2021-12-09T17:38:45.101778Z",
     "iopub.status.idle": "2021-12-09T17:42:39.102841Z",
     "shell.execute_reply": "2021-12-09T17:42:39.103324Z",
     "shell.execute_reply.started": "2021-12-08T21:29:48.161032Z"
    },
    "papermill": {
     "duration": 234.042399,
     "end_time": "2021-12-09T17:42:39.103489",
     "exception": false,
     "start_time": "2021-12-09T17:38:45.061090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size : 905946\n"
     ]
    }
   ],
   "source": [
    "max_features = 8192\n",
    "maxlen = 128\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "allied-jacob",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:42:39.146191Z",
     "iopub.status.busy": "2021-12-09T17:42:39.144306Z",
     "iopub.status.idle": "2021-12-09T17:42:39.982688Z",
     "shell.execute_reply": "2021-12-09T17:42:39.982059Z",
     "shell.execute_reply.started": "2021-12-08T21:34:39.735945Z"
    },
    "papermill": {
     "duration": 0.861115,
     "end_time": "2021-12-09T17:42:39.982813",
     "exception": false,
     "start_time": "2021-12-09T17:42:39.121698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "with open('amazon_dictionary.txt', 'w') as file:\n",
    "    for key in word_index.keys():\n",
    "        file.write(key + \" \" + str(word_index[key]) + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fallen-spotlight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:42:40.046337Z",
     "iopub.status.busy": "2021-12-09T17:42:40.035996Z",
     "iopub.status.idle": "2021-12-09T17:46:36.668179Z",
     "shell.execute_reply": "2021-12-09T17:46:36.667687Z",
     "shell.execute_reply.started": "2021-12-08T21:34:40.77233Z"
    },
    "papermill": {
     "duration": 236.667676,
     "end_time": "2021-12-09T17:46:36.668398",
     "exception": false,
     "start_time": "2021-12-09T17:42:40.000722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_token = tokenizer.texts_to_sequences(train_text)\n",
    "testing_token = tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dated-bhutan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:46:36.722338Z",
     "iopub.status.busy": "2021-12-09T17:46:36.717192Z",
     "iopub.status.idle": "2021-12-09T17:47:51.708334Z",
     "shell.execute_reply": "2021-12-09T17:47:51.707826Z",
     "shell.execute_reply.started": "2021-12-08T21:38:55.605176Z"
    },
    "papermill": {
     "duration": 75.021684,
     "end_time": "2021-12-09T17:47:51.708476",
     "exception": false,
     "start_time": "2021-12-09T17:46:36.686792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(training_token, maxlen = maxlen, padding = 'post')\n",
    "x_test = pad_sequences(testing_token, maxlen = maxlen, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pleased-suspect",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:47:51.749809Z",
     "iopub.status.busy": "2021-12-09T17:47:51.749300Z",
     "iopub.status.idle": "2021-12-09T17:47:53.056740Z",
     "shell.execute_reply": "2021-12-09T17:47:53.055745Z",
     "shell.execute_reply.started": "2021-12-08T21:40:19.880515Z"
    },
    "papermill": {
     "duration": 1.329887,
     "end_time": "2021-12-09T17:47:53.056874",
     "exception": false,
     "start_time": "2021-12-09T17:47:51.726987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last = True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beneficial-manitoba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:47:53.104402Z",
     "iopub.status.busy": "2021-12-09T17:47:53.102609Z",
     "iopub.status.idle": "2021-12-09T17:47:53.104976Z",
     "shell.execute_reply": "2021-12-09T17:47:53.105417Z",
     "shell.execute_reply.started": "2021-12-08T21:40:20.986111Z"
    },
    "papermill": {
     "duration": 0.030675,
     "end_time": "2021-12-09T17:47:53.105548",
     "exception": false,
     "start_time": "2021-12-09T17:47:53.074873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        #self.conv = nn.Conv1d(embedding_dim, 8, kernel_size=5)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        #self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        #print(x.shape)\n",
    "        if len(x) != 1:\n",
    "            batch_size = x.size(0)\n",
    "        else:\n",
    "            batch_size = 1\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "\n",
    "        #conv = self.conv(x)\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        #hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "        #             weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opponent-mirror",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:47:53.144306Z",
     "iopub.status.busy": "2021-12-09T17:47:53.143623Z",
     "iopub.status.idle": "2021-12-09T17:47:53.146336Z",
     "shell.execute_reply": "2021-12-09T17:47:53.145890Z",
     "shell.execute_reply.started": "2021-12-08T21:40:21.00062Z"
    },
    "papermill": {
     "duration": 0.023861,
     "end_time": "2021-12-09T17:47:53.146499",
     "exception": false,
     "start_time": "2021-12-09T17:47:53.122638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sustained-jenny",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:47:53.188641Z",
     "iopub.status.busy": "2021-12-09T17:47:53.188089Z",
     "iopub.status.idle": "2021-12-09T17:47:59.200401Z",
     "shell.execute_reply": "2021-12-09T17:47:59.199766Z",
     "shell.execute_reply.started": "2021-12-08T21:40:21.018613Z"
    },
    "papermill": {
     "duration": 6.036847,
     "end_time": "2021-12-09T17:47:59.200564",
     "exception": false,
     "start_time": "2021-12-09T17:47:53.163717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9059721\n"
     ]
    }
   ],
   "source": [
    "output_size = 1\n",
    "embedding_dim = 10\n",
    "hidden_dim = 4\n",
    "n_layers = 1\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(model_params(model))\n",
    "model.to(device)\n",
    "lr=0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "chinese-poultry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T17:47:59.247560Z",
     "iopub.status.busy": "2021-12-09T17:47:59.246966Z",
     "iopub.status.idle": "2021-12-09T18:18:13.258483Z",
     "shell.execute_reply": "2021-12-09T18:18:13.257859Z",
     "shell.execute_reply.started": "2021-12-08T21:40:22.585467Z"
    },
    "papermill": {
     "duration": 1814.039378,
     "end_time": "2021-12-09T18:18:13.258615",
     "exception": false,
     "start_time": "2021-12-09T17:47:59.219237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5000... Loss: 0.300865... Val Loss: 0.342605\n",
      "Validation loss decreased (inf --> 0.342605).  Saving model ...\n",
      "Epoch: 1/2... Step: 10000... Loss: 0.431972... Val Loss: 0.314555\n",
      "Validation loss decreased (0.342605 --> 0.314555).  Saving model ...\n",
      "Epoch: 1/2... Step: 15000... Loss: 0.413272... Val Loss: 0.314532\n",
      "Validation loss decreased (0.314555 --> 0.314532).  Saving model ...\n",
      "Epoch: 1/2... Step: 20000... Loss: 0.270539... Val Loss: 0.312340\n",
      "Validation loss decreased (0.314532 --> 0.312340).  Saving model ...\n",
      "Epoch: 1/2... Step: 25000... Loss: 0.435059... Val Loss: 0.306707\n",
      "Validation loss decreased (0.312340 --> 0.306707).  Saving model ...\n",
      "Epoch: 1/2... Step: 30000... Loss: 0.526650... Val Loss: 0.314316\n",
      "Epoch: 1/2... Step: 35000... Loss: 0.430606... Val Loss: 0.311327\n",
      "Epoch: 1/2... Step: 40000... Loss: 0.467348... Val Loss: 0.321383\n",
      "Epoch: 1/2... Step: 45000... Loss: 0.410353... Val Loss: 0.315261\n",
      "Epoch: 1/2... Step: 50000... Loss: 0.604215... Val Loss: 0.499141\n",
      "Epoch: 1/2... Step: 55000... Loss: 0.400210... Val Loss: 0.364822\n",
      "Epoch: 1/2... Step: 60000... Loss: 0.477523... Val Loss: 0.366149\n",
      "Epoch: 1/2... Step: 65000... Loss: 0.586521... Val Loss: 0.367774\n",
      "Epoch: 1/2... Step: 70000... Loss: 0.469846... Val Loss: 0.369456\n",
      "Epoch: 2/2... Step: 75000... Loss: 0.384000... Val Loss: 0.390388\n",
      "Epoch: 2/2... Step: 80000... Loss: 0.443989... Val Loss: 0.386008\n",
      "Epoch: 2/2... Step: 85000... Loss: 0.382782... Val Loss: 0.378283\n",
      "Epoch: 2/2... Step: 90000... Loss: 0.488803... Val Loss: 0.400607\n",
      "Epoch: 2/2... Step: 95000... Loss: 0.381273... Val Loss: 0.375204\n",
      "Epoch: 2/2... Step: 100000... Loss: 0.468672... Val Loss: 0.390323\n",
      "Epoch: 2/2... Step: 105000... Loss: 0.426398... Val Loss: 0.388799\n",
      "Epoch: 2/2... Step: 110000... Loss: 0.590725... Val Loss: 0.389672\n",
      "Epoch: 2/2... Step: 115000... Loss: 0.415766... Val Loss: 0.392532\n",
      "Epoch: 2/2... Step: 120000... Loss: 0.527656... Val Loss: 0.382671\n",
      "Epoch: 2/2... Step: 125000... Loss: 0.431358... Val Loss: 0.394440\n",
      "Epoch: 2/2... Step: 130000... Loss: 0.429701... Val Loss: 0.384309\n",
      "Epoch: 2/2... Step: 135000... Loss: 0.533316... Val Loss: 0.400324\n",
      "Epoch: 2/2... Step: 140000... Loss: 0.619212... Val Loss: 0.414498\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "counter = 0\n",
    "print_every = 5000\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(BATCH_SIZE)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = criterion(output, labels.float())\n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(BATCH_SIZE)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in test_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out, lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "related-circuit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T18:18:13.315428Z",
     "iopub.status.busy": "2021-12-09T18:18:13.314610Z",
     "iopub.status.idle": "2021-12-09T18:18:13.317480Z",
     "shell.execute_reply": "2021-12-09T18:18:13.317031Z"
    },
    "papermill": {
     "duration": 0.032686,
     "end_time": "2021-12-09T18:18:13.317597",
     "exception": false,
     "start_time": "2021-12-09T18:18:13.284911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = model.init_hidden(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "british-interstate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T18:18:13.372703Z",
     "iopub.status.busy": "2021-12-09T18:18:13.371907Z",
     "iopub.status.idle": "2021-12-09T18:18:13.408449Z",
     "shell.execute_reply": "2021-12-09T18:18:13.407936Z"
    },
    "papermill": {
     "duration": 0.065734,
     "end_time": "2021-12-09T18:18:13.408578",
     "exception": false,
     "start_time": "2021-12-09T18:18:13.342844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7290], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I love this film, it was so awesome!\"\n",
    "trial = torch.tensor(pad_sequences(tokenizer.texts_to_sequences([sentence]), maxlen = maxlen)).to(device)\n",
    "\n",
    "model(trial, h)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "secret-lebanon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T18:18:13.463953Z",
     "iopub.status.busy": "2021-12-09T18:18:13.463364Z",
     "iopub.status.idle": "2021-12-09T18:18:13.736157Z",
     "shell.execute_reply": "2021-12-09T18:18:13.735677Z"
    },
    "papermill": {
     "duration": 0.30168,
     "end_time": "2021-12-09T18:18:13.736328",
     "exception": false,
     "start_time": "2021-12-09T18:18:13.434648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/opt/conda/lib/python3.7/site-packages/torch/onnx/symbolic_opset9.py:1805: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  \"or define the initial states (h0/c0) as inputs of the model. \")\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  (trial, (torch.randn(1,1,4).to(device), torch.randn(1,1,4).to(device))),                   # model input (or a tuple for multiple inputs)\n",
    "                  \"lstm-PT.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2676.210622,
   "end_time": "2021-12-09T18:18:19.071868",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-09T17:33:42.861246",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
